version: "3"
services:
  namenode:
    image: dhimasarbi/hadoop:latest
    command: bash -c "/etc/run.sh start namenode"
    ports:
      - target: 9870
        published: 9870
        protocol: tcp
        mode: host
      - target: 8088
        published: 8088
        protocol: tcp
        mode: host
    hostname: namenode
    networks:
      - cluster-network
    volumes:
      - /hadoop/hadoop/data:/home/user/data
      - hdfs-master-data:/home/hadoop/data/nameNode
      - hdfs-master-checkpoint-data:/home/hadoop/data/namesecondary
    deploy:
      mode: global
      endpoint_mode: dnsrr
      placement:
        constraints:
          - node.labels.role == master

  datanode1:
    image: dhimasarbi/hadoop:latest
    command: bash -c "/etc/run.sh start"
    hostname: datanode1
    depends_on:
      - "namenode"
    volumes:
      - hdfs-worker-data:/home/hadoop/data/dataNode
    networks:
      - cluster-network
    deploy:
      placement:
        constraints:
          - node.labels.role == worker
  datanode2:
    image: dhimasarbi/hadoop:latest
    command: bash -c "/etc/run.sh start"
    hostname: datanode2
    depends_on:
      - "namenode"
    volumes:
      - hdfs-worker-data:/home/hadoop/data/dataNode
    networks:
      - cluster-network
    deploy:
      placement:
        constraints:
          - node.labels.role == worker
  datanode3:
    image: dhimasarbi/hadoop:latest
    command: bash -c "/etc/run.sh start"
    hostname: datanode3
    depends_on:
      - "namenode"
    volumes:
      - hdfs-worker-data:/home/hadoop/data/dataNode
    networks:
      - cluster-network
    deploy:
      placement:
        constraints:
          - node.labels.role == worker

volumes:
  hdfs-master-data:
    name: "hdfs_master_data_swarm"
    external: true
  hdfs-master-checkpoint-data:
    name: "hdfs_master_checkpoint_data_swarm"
    external: true
  hdfs-worker-data:
    name: "hdfs_worker_data_swarm"
    external: true

networks:
  cluster-network:
    external: true
    name: cluster_net_swarm
