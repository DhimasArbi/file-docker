# Use the Ubuntu base image
FROM eclipse-temurin:8-jdk

USER root
ARG TARGETPLATFORM
ENV HDV=3.3.5

SHELL ["/bin/bash", "-c"]

ENV HADOOP_HOME "/usr/local/hadoop"

# Update the package repository and install Java
RUN apt update \
    && export DEBIAN_FRONTEND=noninteractive \
    && apt install -y --no-install-recommends \
    nano curl iputils-ping ssh \
    openssh-server openssh-client \
    && rm -rf /var/lib/apt/lists/*

RUN echo 'ssh:ALL:allow' >> /etc/hosts.allow \
    && echo 'sshd:ALL:allow' >> /etc/hosts.allow \
    && ssh-keygen -q -t rsa -N '' -f ~/.ssh/id_rsa \
    && cat ~/.ssh/id_rsa.pub > ~/.ssh/authorized_keys \
    && echo 'PermitRootLogin yes' >> /etc/ssh/sshd_config \
    && service ssh restart

# Download and extract Hadoop
RUN if [[ "$TARGETPLATFORM" == "linux/amd64" ]]; then \
        curl https://dlcdn.apache.org/hadoop/common/stable/hadoop-$HDV.tar.gz | tar -xz ; \
    fi
        
RUN if [[ "$TARGETPLATFORM" == "linux/arm64" ]]; then \
        curl https://dlcdn.apache.org/hadoop/common/stable/hadoop-$HDV-aarch64.tar.gz | tar -xz ; \
    fi

RUN mv hadoop-$HDV /usr/local/hadoop \
    && echo 'export JAVA_HOME=/opt/java/openjdk' >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh \
    && echo 'export PATH=$PATH:$HADOOP_HOME/bin' >> ~/.bashrc \
    && echo 'export PATH=$PATH:$HADOOP_HOME/sbin' >> ~/.bashrc 

# Set the environment variables for Hadoop
ENV HADOOP_COMMON_HOME $HADOOP_HOME
ENV HADOOP_HDFS_HOME $HADOOP_HOME
ENV HADOOP_MAPRED_HOME $HADOOP_HOME
ENV HADOOP_YARN_HOME $HADOOP_HOME
ENV HADOOP_CONF_DIR $HADOOP_HOME/etc/hadoop

# Adds some needed environment variables
ENV HDFS_NAMENODE_USER "root"
ENV HDFS_DATANODE_USER "root"
ENV HDFS_SECONDARYNAMENODE_USER "root"
ENV YARN_RESOURCEMANAGER_USER "root"
ENV YARN_NODEMANAGER_USER "root"

# ENV PS1='\u@\h:\w\a\$ '

# Copy the configuration files
WORKDIR /usr/local/hadoop/etc/hadoop
COPY ./config/core-site.xml \
    ./config/hdfs-site.xml \
    ./config/mapred-site.xml \
    ./config/yarn-site.xml \
    ./config/workers ./

WORKDIR /etc
COPY ./config/run.sh .
RUN chmod +x /etc/run.sh \
    && ln -s /etc/run.sh /usr/bin/bdcluster && chmod 700 /usr/bin/bdcluster

WORKDIR /home/hadoop
RUN mkdir data

# Start the Namenode and Datanode
CMD service ssh start && sleep infinity
